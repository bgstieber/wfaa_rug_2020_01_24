---
title: "Reading Data into R"
author: "Brad Stieber"
date: "Presented to WFAA R Users Group on 2020-01-24"
output: 
  html_document: 
    toc: yes
    toc_depth: 3
    toc_float: true
---

<!--

how many different ways are there to read data in to R?

1. read.csv (stringsAsFactors)
2. read_csv
3. read_excel
4. fread
5. database

how many different data types are there?

1. gold standard csv
2. good csv, but weird strings for NA
3. decent csv, but data doesn't start at first row 
4. decent csv, but header row is detached from data
5. excel file
6. a big honkin file
7. tables/query in SQL


data set creation:

write.table(head(iris), 
            file = "iris.txt", sep = ",", row.names = FALSE)

NAs: 9999 and ""

write.table(head(iris), 
            file = "iris_weird_NA.txt", sep = ",", row.names = FALSE)

write.table(head(iris), 
            file = "iris_pipe_delim.txt", sep = "|", row.names = FALSE)

-->

## Introduction

Today, we're going to be taking a quick ride through a few ways to get data from flat files (txt, csv, excel) into R.

Here are links to the documentation for each of the functions discussed.

- [`read.table`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html)
- [`readr::read_delim`](https://readr.tidyverse.org/reference/read_delim.html)
- [`data.table::fread`](https://rdatatable.gitlab.io/data.table/reference/fread.html)
- [`readxl::read_excel`](https://readxl.tidyverse.org/reference/read_excel.html)

## Examples {.tabset .tabset-pills}

### read.csv - basics

The first function you probably used to read data into R was [`read.csv`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html).

Let's suppose you get a basic flat file

```
"Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species"
5.1,3.5,1.4,0.2,"setosa"
4.9,3,1.4,0.2,"setosa"
4.7,3.2,1.3,0.2,"setosa"
4.6,3.1,1.5,0.2,"setosa"
5,3.6,1.4,0.2,"setosa"
5.4,3.9,1.7,0.4,"setosa"
```

Using `read.csv` results in:

```{r}
dat <- read.csv("data/iris.txt")
tail(dat)
```

But wait, something weird happened with `Species`:

```{r}
dat$Species
```

`read.csv` has an argument called `stringsAsFactors`, and its default is TRUE. This means that any string/character type columns you have in your data will be converted to factors (further reading: [stringsAsFactors: An unauthorized biography](https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/)). This is generally not what we want. 

So, in the event that I use `read.csv` (I typically prefer `readr::read_csv` or `data.table::fread`, discussed below), I set `stringsAsFactors = FALSE`.

```{r}
dat2 <- read.csv("data/iris.txt", stringsAsFactors = FALSE)
dat2$Species
```

`read.csv` works really well without specifying many arguments when your data is nice. What happens if your data is a little messier?

### read.table - Column headers are separated, weird delimiter

Here's the data:

```
"Sepal.Length"|"Sepal.Width"|"Petal.Length"|"Petal.Width"|"Species"
----------------------------------------------------------------- 
5.1|3.5|1.4|0.2|"setosa"
4.9|3|1.4|0.2|"setosa"
4.7|3.2|1.3|0.2|"setosa"
4.6|3.1|1.5|0.2|"setosa"
5|3.6|1.4|0.2|"setosa"
5.4|3.9|1.7|0.4|"setosa"
```

Two things are weird with this data

1. Column headers are separated from the data with `---`
2. A pipe (`|`) delimiter is used

These two oddities require that we use `read.table` instead of `read.csv`.

```{r}
# first, get column names from first row of data
column_names <- read.table("data/iris_pipe_delim_edit.txt",
                           sep = "|", # pipe delim
                           nrows = 1, # only read first row
                           stringsAsFactors = FALSE,
                           header = FALSE) # no headers
# convert to a character vector
(column_names <- as.character(column_names))
# then, read in remaining rows, using `skip` argument
full_data <- read.table("data/iris_pipe_delim_edit.txt",
                        sep = "|",
                        skip = 2, # skip first 2 rows
                        stringsAsFactors = FALSE,
                        col.names = column_names)

tail(full_data)
```

### read.csv - Missing Values are Coded Strangely

```
"Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species"
5.1,3.5,1.4,0.2,"setosa"
4.9,3,1.4,0.2,"setosa"
4.7,3.2,NULL,0.2,"setosa"
4.6,3.1,1.5,0.2,"setosa"
5,MISSING,1.4,0.2,"setosa"
5.4,3.9,9999,0.4,"setosa"
```
By default, when you're reading in data with the `read.table`/`read.csv` family of functions, R treats any columns containing the string `"NA"` as an `NA` value. Sometimes we have missing values that take other values, like `999`, `""`, and `NULL`. Using the `na.strings` argument can help us with this. 

```{r}
dat_default_NA <- read.csv("data/iris_weird_NA_edit.txt",
                           stringsAsFactors = FALSE)

dat_default_NA$Sepal.Width
dat_default_NA$Petal.Length
```

Since `R` found character values in the `Sepal.Width` and `Petal.Length` columns, it treats those as characters. We know this is wrong, and can fix it using `na.strings`.

```{r}
dat_default_NA <- read.csv("data/iris_weird_NA_edit.txt",
                           stringsAsFactors = FALSE,
                           na.strings = c("NULL", "9999", "MISSING"))

dat_default_NA$Sepal.Width
dat_default_NA$Petal.Length
```

### readr::read_csv

```{r}
library(readr)
```

The next function I want to talk about is `read_csv` from the [__`readr`__](https://readr.tidyverse.org/) package.

This function is really helpful, and it's pretty much my go-to function to read in flat files into R. It has good and well-reasoned defaults (no `stringsAsFactors = FALSE`!), and reads in the data as a [`tibble`](https://tibble.tidyverse.org/) as opposed to a `data.frame`. This makes printing the data to your console a lot better. 

Rather than looking at the boring iris data, we'll instead read some data from the internet. 

```{r cache = TRUE}
u1 <- "https://raw.githubusercontent.com/fivethirtyeight/data"

u2 <- "/master/college-majors/all-ages.csv"

(u <- paste0(u1, u2))

college_data <- read_csv(u) # informative parsing printing

college_data # nice printing of data, don't need head() or tail()
```

`read_csv` has a few arguments I should highlight:

- __`na`__: Character vector of strings to interpret as missing values. (this is like `na.strings` in `read.csv`)
- __`skip`__: Number of lines to skip before reading data.
- __`n_max`__: Maximum number of records to read.
- __`col_types`__: allows you to specify the column types for your data. I typically leave this as the default, but it can be helpful if you're trying to coerce a certain column to certain data type

### data.table::fread

```{r}
library(data.table)
```

Now, sometimes I'm dealing with some really nasty data set that is large and unwieldy. `read_csv` is good for maybe 80-90% of data inputs, but sometimes we need something more powerful.

There is where the `fread` function from the [__`data.table`__](https://rdatatable.gitlab.io/data.table/) package comes in handy (further reading: [Convenience features of fread](https://github.com/Rdatatable/data.table/wiki/Convenience-features-of-fread)).

By [some measures](https://jozef.io/r917-fread-comparisons/), `fread` can be about 6 times faster than `read.csv` and about 2.5 times faster than `read_csv`.

One of the best parts of `fread` is that you do not necessarily have to specify the delimiter in your data.

For example, the pipe delimited data from above is read in easily.

```{r}
pipe_dat <- fread("data/iris_pipe_delim_edit.txt",
                  skip = 2,
                  verbose = TRUE,
                  col.names = names(iris))

pipe_dat
```

Here's a demonstration of how much faster `fread` is than `read.csv` and `read_csv` using a subset of the flights data set.

```{r cache = TRUE}
u1 <- "https://github.com/roberthryniewicz/datasets/"
u2 <- "blob/master/airline-dataset/flights/flights.csv?raw=true"
uu <- paste0(u1, u2)

system.time(dat_base <- read.csv(uu)) # timing for read.csv
system.time(dat_readr <- read_csv(uu)) # timing for read_csv
system.time(dat_fread <- fread(uu)) # timing for fread
```

```{r}
dim(dat_fread) # rows by columns
```

I would strongly encourage you to spend some time playing around with `fread`, and investigating its arguments.

Considering all the benefits of `fread`, I'm actually surprised I don't use it more. 

### readxl::read_excel



## Further Reading

Here are the links I've referenced:

#### Articles

- [stringsAsFactors: An unauthorized biography](https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/)
- [Convenience features of fread](https://github.com/Rdatatable/data.table/wiki/Convenience-features-of-fread)
- [How data.table's fread can save you a lot of time and memory, and take input from shell commands](https://jozef.io/r917-fread-comparisons/)

#### Package Sites

- [The __`readr`__ package](https://readr.tidyverse.org/)
- [The __`tibble`__ package](https://tibble.tidyverse.org/)
- [The __`data.table`__ package](https://rdatatable.gitlab.io/data.table/)

#### Documentation

- [`read.table` docs](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html)
- [`readr::read_delim` docs](https://readr.tidyverse.org/reference/read_delim.html)
- [`data.table::fread` docs](https://rdatatable.gitlab.io/data.table/reference/fread.html)
- [`readxl::read_excel` docs](https://readxl.tidyverse.org/reference/read_excel.html)

## Session Information

```{r}
sessionInfo()
```


