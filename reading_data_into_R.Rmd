---
title: "Reading Data into R"
author: "Brad Stieber"
date: "2020-02-02"
output: html_document
---

This post was originally meant for the R Users Group at my organization. I thought it would be worthwhile to have it on my blog as well, in case anyone out there is searching for a tutorial on reading data into R.

There are a lot of different ways to get data into R, and this post highlights a few of the common ways of doing that.

## Introduction

Today, we're going to be taking a quick ride through a few ways to get data from flat files (txt, csv, excel) into R.

Here are links to the documentation for each of the functions discussed.

- [`read.table`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html)
- [`readr::read_delim`](https://readr.tidyverse.org/reference/read_delim.html)
- [`data.table::fread`](https://rdatatable.gitlab.io/data.table/reference/fread.html)
- [`readxl::read_excel`](https://readxl.tidyverse.org/reference/read_excel.html)

You can find all the code and data [on my GitHub](https://github.com/bgstieber/wfaa_rug_2020_01_24). If you [clone that repository](https://help.github.com/en/desktop/contributing-to-projects/cloning-a-repository-from-github-to-github-desktop) you should be able to run all of this on your own machine.

## Examples {.tabset .tabset-pills}

### read.csv - basics

The first function you probably used to read data into R was [`read.csv`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html).

Let's suppose you get a basic flat file

```
"Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species"
5.1,3.5,1.4,0.2,"setosa"
4.9,3,1.4,0.2,"setosa"
4.7,3.2,1.3,0.2,"setosa"
4.6,3.1,1.5,0.2,"setosa"
5,3.6,1.4,0.2,"setosa"
5.4,3.9,1.7,0.4,"setosa"
```

Using `read.csv` results in:

```{r}
dat <- read.csv("data/iris.txt")
tail(dat)
```

But wait, something weird happened with `Species`:

```{r}
dat$Species
```

`read.csv` has an argument called `stringsAsFactors`, and its default is TRUE. This means that any string/character type columns you have in your data will be converted to factors (further reading: [stringsAsFactors: An unauthorized biography](https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/)). This is generally not what we want. 

So, in the event that I use `read.csv` (I typically prefer `readr::read_csv` or `data.table::fread`, discussed below), I set `stringsAsFactors = FALSE`.

```{r}
dat2 <- read.csv("data/iris.txt", stringsAsFactors = FALSE)
dat2$Species
```

`read.csv` works really well without specifying many arguments when your data is nice. What happens if your data is a little messier?

### read.table - Column headers are separated, weird delimiter

Here's the data:

```
"Sepal.Length"|"Sepal.Width"|"Petal.Length"|"Petal.Width"|"Species"
-----------------------------------------------------------------
----------------------------------------------------------------- 
5.1|3.5|1.4|0.2|"setosa"
4.9|3|1.4|0.2|"setosa"
4.7|3.2|1.3|0.2|"setosa"
4.6|3.1|1.5|0.2|"setosa"
5|3.6|1.4|0.2|"setosa"
5.4|3.9|1.7|0.4|"setosa"
```

Two things are weird with this data

1. Column headers are separated from the data with two rows `---`
    - Use `skip` argument
2. A pipe (`|`) delimiter is used
    - Use `sep = "|"` argument

These two oddities require that we use `read.table` instead of `read.csv`.

```{r}
# first, get column names from first row of data
column_names <- read.table("data/iris_pipe_delim_edit.txt",
                           sep = "|", # pipe delim
                           nrows = 1, # only read first row
                           stringsAsFactors = FALSE,
                           header = FALSE) # no headers
# convert to a character vector
(column_names <- as.character(column_names))
# then, read in remaining rows, using `skip` argument
full_data <- read.table("data/iris_pipe_delim_edit.txt",
                        sep = "|",
                        skip = 3, # skip first 3 rows
                        stringsAsFactors = FALSE,
                        col.names = column_names) # specify column names

tail(full_data)
```

### read.csv - Missing Values are Coded Strangely

What if our data has weird missing value codes, maybe due to human input.

```
"Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species"
5.1,3.5,1.4,0.2,"setosa"
4.9,3,1.4,0.2,"setosa"
4.7,3.2,NULL,0.2,"setosa"
4.6,3.1,1.5,0.2,"setosa"
5,MISSING,1.4,0.2,"setosa"
5.4,3.9,9999,0.4,"setosa"
```
By default, when you're reading in data with the `read.table`/`read.csv` family of functions, R treats any columns containing the string `"NA"` as an `NA` value. Sometimes we have missing values that take other values, like `999`, `""`, and `NULL`. Using the `na.strings` argument can help us with this. 

```{r}
dat_default_NA <- read.csv("data/iris_weird_NA_edit.txt", 
                           stringsAsFactors = FALSE)

dat_default_NA$Sepal.Width
dat_default_NA$Petal.Length
```

Since `R` found character values in the `Sepal.Width` and `Petal.Length` columns, it treats those as characters. We know this is wrong, and can fix it using `na.strings`.

```{r}
dat_default_NA <- read.csv("data/iris_weird_NA_edit.txt",
                           stringsAsFactors = FALSE,
                           na.strings = c("NULL", "9999", "MISSING"))

dat_default_NA$Sepal.Width
dat_default_NA$Petal.Length
```

### readr::read_csv

```{r}
library(readr)
```

The next function I want to talk about is `read_csv` from the [__`readr`__](https://readr.tidyverse.org/) package.

This function is really helpful, __and it's pretty much my go-to function to read in flat files into R__. It has good and well-reasoned defaults (no `stringsAsFactors = FALSE`!), and reads in the data as a [`tibble`](https://tibble.tidyverse.org/) as opposed to a `data.frame`. This makes printing the data to your console a lot better. 

Rather than looking at the boring iris data, we'll instead read some data from the internet. Yes, if you give one of the `read` functions (even `read.table`!) a url with a csv/txt file, it will be able to read that into R (conditional on you having a connection to the internet).

```{r cache = TRUE}
u1 <- "https://raw.githubusercontent.com/fivethirtyeight/data"

u2 <- "/master/college-majors/all-ages.csv"

(u <- paste0(u1, u2))

college_data <- read_csv(u) # informative parsing printing

college_data # nice printing of data, don't need head() or tail()
```

`read_csv` has a few arguments I should highlight:

- __`na`__: Character vector of strings to interpret as missing values. (this is like `na.strings` in `read.csv`)
- __`skip`__: Number of lines to skip before reading data.
- __`n_max`__: Maximum number of records to read.
- __`col_types`__: allows you to specify the column types for your data. __I typically leave this as is, and let the parser do its job__, but it can be helpful if you're trying to coerce a certain column to certain data type

### data.table::fread

```{r}
library(data.table)
```

Now, sometimes you might be dealing with some really nasty data that is large and unwieldy. `read_csv` is good for maybe 80-90% of data files, but sometimes we need something more powerful.

There is where the `fread` function from the [__`data.table`__](https://rdatatable.gitlab.io/data.table/) package comes in handy (further reading: [Convenience features of fread](https://github.com/Rdatatable/data.table/wiki/Convenience-features-of-fread)).

By [some measures](https://jozef.io/r917-fread-comparisons/), `fread` can be about 6 times faster than `read.csv` and about 2.5 times faster than `read_csv`.

One of the best parts of `fread` is that you do not necessarily have to specify the delimiter in your data.

For example, the pipe delimited data from above is read in easily. In the code below I set `verbose = TRUE` to show the internal output from `fread`. In general, I'd recommend you leave this as FALSE, unless you're in serious debug mode.

```{r}
pipe_dat <- fread("data/iris_pipe_delim_edit.txt",
                  skip = 3, # homework: what happens if you don't specify skip?
                  verbose = TRUE, # default is FALSE, which I recommend
                  col.names = names(iris))

pipe_dat
```

Here's a demonstration of how much faster `fread` is than `read.csv` and `read_csv` using a subset of the flights data set.

```{r cache = TRUE}
u1 <- "https://github.com/roberthryniewicz/datasets/"
u2 <- "blob/master/airline-dataset/flights/flights.csv?raw=true"
(uu <- paste0(u1, u2))

system.time(dat_base <- read.csv(uu)) # timing for read.csv
system.time(dat_readr <- read_csv(uu)) # timing for read_csv
system.time(dat_fread <- fread(uu)) # timing for fread
```

```{r}
dim(dat_fread) # rows by columns
```

I would strongly encourage you to spend some time playing around with `fread`, and thoroughly investigate its arguments (it's got a lot!). 

Considering all the benefits of `fread`, I'm actually surprised I don't use it more. 

### readxl::read_excel

```{r}
library(readxl)
```

Maybe you've been unlucky enough to have to do some analysis using an excel file. This used to be a tedious task to get the data into R. Now, we can use the `read_excel` function from the [__`readxl`__](https://readxl.tidyverse.org/index.html) package.

Excel files will typically have multiple sheets. The [excel example](https://community.tableau.com/servlet/JiveServlet/downloadBody/1236-102-2-15278/Sample%20-%20Superstore.xls) we're looking at today has three separate sheets.

Reading these in is straightforward, using the `read_excel` function and the `sheet` argument.

```{r}
orders <- read_excel("data/Superstore.xls",
                     sheet = "Orders")
tail(orders)

returns <- read_excel("data/Superstore.xls",
                      sheet = "Returns")

tail(returns)

people <- read_excel("data/Superstore.xls",
                     sheet = "People")

tail(people)
```

A few things to note about `read_excel`

- __VERY IMPORTANT__ Sometimes the function fails if you have the file open. Make sure the excel file is closed before trying to read it into R!
- The function will inform you of parsing issues/column type coercion.
- By default, the function will return a `tibble` and not a `data.frame`.

## Wrapping Up

Today, we've looked at a few different ways of getting data into R from flat files. For nice flat files, it's pretty straightforward to get your data into R. If your data isn't so nice, you can generally be successful using the `fread` or `read_csv` functions, but you'll need to be very aware of the structure of your data, as well as the arguments for whatever function decide to use.

## Further Reading

Here are the links I've referenced.

#### Articles

- [stringsAsFactors: An unauthorized biography](https://simplystatistics.org/2015/07/24/stringsasfactors-an-unauthorized-biography/)
- [Convenience features of fread](https://github.com/Rdatatable/data.table/wiki/Convenience-features-of-fread)
- [How data.table's fread can save you a lot of time and memory, and take input from shell commands](https://jozef.io/r917-fread-comparisons/)

#### Package Sites

- [__`readr`__](https://readr.tidyverse.org/)
- [__`tibble`__](https://tibble.tidyverse.org/)
- [__`data.table`__](https://rdatatable.gitlab.io/data.table/)
- [__`readxl`__](https://readxl.tidyverse.org/index.html)

#### Function Documentation

- [`read.table`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html)
- [`readr::read_delim`](https://readr.tidyverse.org/reference/read_delim.html)
- [`data.table::fread`](https://rdatatable.gitlab.io/data.table/reference/fread.html)
- [`readxl::read_excel`](https://readxl.tidyverse.org/reference/read_excel.html)

## Session Information

```{r}
sessionInfo()
```


